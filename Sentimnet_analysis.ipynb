{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bac9d7-9282-4204-8f26-d0aad8a3b7d5",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of Sephora Skincare Review Data Set:\n",
    "\n",
    "A natural language processing approach called sentiment analysis is used to identify the sentiment or emotion expressed in a text. Sentiment analysis can be used to examine the overall sentiment surrounding Sephora skincare goods by applying it to customer reviews or other text data.\n",
    "\n",
    "Sentiment analysis for Sephora skincare goods aims to categorize customer reviews as favorable, negative, or neutral automatically. This can be used to better understand how consumers generally feel about various skincare brands or products.\n",
    "\n",
    "- Perform sentiment analysis on customer reviews to understand the overall sentiment (positive, negative, or neutral).\n",
    "- Use natural language processing techniques to classify reviews and extract sentiment-related information.\n",
    "- Visualize sentiment patterns using bar plots or word clouds to identify popular sentiment trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7ea2c-7a67-43d4-984f-4b33b2dda685",
   "metadata": {},
   "source": [
    "# Different Approaches for Sentiment Analysis\n",
    "There are various ways to sentiment analysis, each with its own set of benefits and drawbacks. Here are some typical approaches to sentiment analysis:\n",
    "- Lexicon-based Sentiment Analysis: This method uses sentiment lexicons or dictionaries that contain words or phrases related to sentiment scores. Sentiment scores are assigned to words in the text that match entries in the lexicon, and an overall sentiment score is generated.\n",
    "- Rule-based Sentiment Analysis: Predefined rules or patterns are used to identify sentiment in text in rule-based sentiment analysis. Keywords, linguistic patterns, or grammatical structures can all be used to generate these rules. Specific words or phrases, for example, may express positive or negative sentiment.\n",
    "- Machine Learning Classification: Machine learning algorithms can be trained on labeled datasets to classify text into positive, negative, or neutral sentiment categories. This method entails extracting features such as bag-of-words or word embeddings and training a classifier such as Naive Bayes, Support Vector Machines (SVM), or neural networks.\n",
    "- Deep Learning: For sentiment analysis, transformer-based models such as BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pre-trained Transformer), and XLNet (Generalized Autoregressive Pretraining for Language Understanding) can be used. To categorize sentiment, these algorithms may learn complicated patterns and correlations in text data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb360f-401d-4b86-904e-6a330cc6a7df",
   "metadata": {},
   "source": [
    "# Why BERT is a Preferred Choice for Sentiment Analysis ?\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a well-known and powerful model in natural language processing, including sentiment analysis. BERT, as a **contextual language model**, can understand the semantic meaning of words by evaluating their context within a phrase. It considers the full sentence and effectively handles complex linguistic structures, such as word relationships, to understand the given meaning and sentiment.\n",
    "\n",
    "BERT's **pre-training** phase on a large corpus of text data, such as  BooksCorpus and English Wikipedia, is one of its primary strengths. As a result of this pre-training, BERT is able to gain extensive language representations that encapsulate the general comprehension of diverse linguistic nuances. BERT can be fine-tuned to be specifically adapted for sentiment analysis tasks by exploiting the knowledge gathered during pre-training. Because of its transfer learning capability, BERT can produce promising outcomes even with insufficient labeled data.\n",
    "\n",
    "Overall, BERT's proficiency in sentiment analysis originates from its contextual awareness, pre-training on varied text sources, **fine-tuning** adaptability, **transfer learning** technique, and capacity to generalize effectively while performing well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19b28a40-b71e-4b57-97b8-9258509f8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "from transformers import BertTokenizer,TFBertForSequenceClassification\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3950af12-2cc5-4840-97bc-a387191c0a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/utility.py:17: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/utility.py:21: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/utility.py:23: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loves_count', 'sephora_exclusive', 'sale_price_usd', 'size', 'brand_id', 'ingredients', 'variation_desc', 'primary_category', 'secondary_category', 'child_max_price', 'child_min_price', 'value_price_usd', 'new', 'variation_value', 'child_count', 'limited_edition', 'online_only', 'variation_type', 'reviews', 'out_of_stock', 'highlights', 'tertiary_category', 'product_id']\n",
      "(1307279, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get function from utiliy class\n",
    "root=os.getcwd()\n",
    "from utility import Utility\n",
    "util=Utility()\n",
    "util.read_all_data()\n",
    "df=util.data_df.copy()\n",
    "# get positive reviews and negative reviews\n",
    "# select labeled reviews. if is_recorecommended 1 tells positive and 0 tell negative.\n",
    "review_df=df.loc[~((df['review_text'].isnull())|(df['is_recommended'].isnull())),['review_text','is_recommended']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9710016-0fb8-4ac5-952c-e422dc4920f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_review_data: 0.8395363015197921 928146\n",
      "negative_review_data: 0.16046369848020797 177400\n",
      "1200\n",
      "600.0\n"
     ]
    }
   ],
   "source": [
    "# get weather positive and negative labeled data are balanced  \n",
    "index_pos=review_df.index[(review_df['is_recommended']>0.9)==True]\n",
    "index_neg=review_df.index[(review_df['is_recommended']<0.09)==True]\n",
    "print('positive_review_data:',len(index_pos)/(len(index_pos)+len(index_neg)),len(index_pos))\n",
    "print('negative_review_data:',len(index_neg)/(len(index_pos)+len(index_neg)),len(index_neg))\n",
    "# we see labeled data are unblanced and\n",
    "# the number of label data are large and it takes so much time for training \n",
    "# we chose only 1000 cases for traing and 200 cases for validation \n",
    "index_all=index_pos[:600].union(index_neg[:600])\n",
    "print(len(index_all))\n",
    "# get reviews for encoding \n",
    "review_short_df=review_df.loc[index_all,:].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065b06f8-7a9e-49f8-af3c-0f303007c2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.0522215366363525 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# get word embeddings for Sephora review text using BERT\n",
    "def encode(text):\n",
    "    return tokenizer.encode(text, \n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=128)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# change rveiew as a string so that BERT can encode all strings in the form of numerical vectors. \n",
    "review_short_df['review_text']=review_short_df['review_text'].astype(str)\n",
    "\n",
    "start_time = time.time()\n",
    "texts=review_short_df['review_text'].values.tolist()\n",
    "    \n",
    "    # Create a multiprocessing pool\n",
    "with Pool() as pool:\n",
    "    # Tokenize the texts in parallel\n",
    "    encoded_texts = pool.map(encode, texts)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d32929df-13ac-4f33-b7f7-f74bc9c6609d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training labels: 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1de2b754bfa40958579c74dcea7b018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:12:39.113454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-02 16:12:39.113918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 712s 20s/step - loss: 0.6810 - accuracy: 0.5810\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 648s 20s/step - loss: 0.4381 - accuracy: 0.8380\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 638s 20s/step - loss: 0.2521 - accuracy: 0.9130\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 632s 20s/step - loss: 0.1407 - accuracy: 0.9560\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 623s 19s/step - loss: 0.0643 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca205c6ca0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "max_length = max(len(tokens) for tokens in encoded_texts)\n",
    "padded_texts = tf.keras.preprocessing.sequence.pad_sequences(encoded_texts, maxlen=max_length, padding='post')\n",
    "# convert in the tesors \n",
    "labels = tf.convert_to_tensor(review_short_df['is_recommended'].to_list())\n",
    "labels = tf.dtypes.cast(labels, tf.int32)\n",
    "\n",
    "# get training data set\n",
    "indices = tf.where(tf.equal(labels, 0))\n",
    "indices_0 = tf.squeeze(indices)\n",
    "indices = tf.where(tf.equal(labels, 1))\n",
    "indices_1 = tf.squeeze(indices)\n",
    "num=500\n",
    "indices_all=tf.concat([indices_0[:num], indices_1[:num]], axis=0)\n",
    "# select label and codes for training         \n",
    "selected_labels = tf.gather(labels, indices_all)\n",
    "selected_padded_texts = tf.gather(padded_texts, indices_all)\n",
    "print('length of training labels:',len(selected_labels))\n",
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices((selected_padded_texts, selected_labels))\n",
    "dataset = dataset.shuffle(len(selected_padded_texts)).batch(batch_size)\n",
    "# Load the pre-trained BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(len(dataset))\n",
    "model.fit(dataset, epochs=5)\n",
    "# model.save_weights(os.path.join(root, 'models','bertWeight'))\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be07d09c-3e25-4e26-8901-40edaf8d3f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 45s 5s/step - loss: 0.3904 - accuracy: 0.9000\n",
      "Validation Loss: 0.39037904143333435\n",
      "Validation Accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "# validation of the model\n",
    "indices_all_val=tf.concat([indices_0[500:600], indices_1[500:600]], axis=0)\n",
    "selected_labels_val = tf.gather(labels, indices_all_val)\n",
    "selected_padded_texts_val = tf.gather(padded_texts, indices_all_val)\n",
    "validation_results = model.evaluate(selected_padded_texts_val, selected_labels_val)\n",
    "print(\"Validation Loss:\", validation_results[0])\n",
    "print(\"Validation Accuracy:\", validation_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373abe4-a913-4420-8dbf-e179b67a29e8",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "Using 5000 positive and negative labeled evaluations for training, the model attained a high accuracy of 99% throughout the training phase. This shows that the model was able to learn from the data provided and generate correct predictions on the training set.\n",
    "\n",
    "- Epoch 1/5\n",
    "    313/313 [==============================] - 2777s 9s/step - loss: 0.3204 - accuracy: 0.8463\n",
    "    Epoch 2/5\n",
    "    313/313 [==============================] - 2790s 9s/step - loss: 0.1445 - accuracy: 0.9507\n",
    "    Epoch 3/5\n",
    "    313/313 [==============================] - 2798s 9s/step - loss: 0.0897 - accuracy: 0.9726\n",
    "    Epoch 4/5\n",
    "    313/313 [==============================] - 2761s 9s/step - loss: 0.0591 - accuracy: 0.9827\n",
    "    Epoch 5/5\n",
    "    313/313 [==============================] - 2742s 9s/step - loss: 0.0388 - accuracy: 0.9888\n",
    "\n",
    "\n",
    "A separate set of 500 good and negative evaluations was utilized to validate the model's performance. On this validation set, the model had an accuracy of 92%. This suggests that the model is performing well on previously unknown data and that it is generalizing its predictions beyond the training set.\n",
    "\n",
    "Based on these findings, it can be assumed that when the model is trained on a bigger dataset that contains all labeled Sephora reviews, it will perform even better in terms of predictive accuracy for sentiment analysis. The increased amount of labeled data will offer the model with more different instances to train from, enhancing its ability to interpret and predict sentiment across a broader variety of evaluations.\n",
    "\n",
    "As a result of using the whole labeled dataset of Sephora reviews, it is realistic to expect the model to display high predictive ability for sentiment analysis tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c507444-4c4f-4996-9e28-bba47fa4c3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
